{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8d4a206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 데이터 로드 및 파싱 준비: labeled_sentences.csv\n",
      "   -> 로드된 총 레코드 수: 74201개 (3200개 가정)\n",
      "   -> 사용된 컬럼 목록: ['text_input', 'command_string']\n",
      "\n",
      "2. 명령 문자열에서 H, S, B, Dimmer, CT 값 파싱 중...\n",
      "   -> 파싱에 성공한 레코드 수: 74162개 (39개 제거됨)\n",
      "\n",
      "3. 데이터 분할: Train (80%) / Validation (20%)\n",
      "   -> 훈련 데이터셋 크기: 59329개\n",
      "   -> 검증 데이터셋 크기: 14833개\n",
      "\n",
      "4. 파일 저장: train_new.jsonl에 JSONL 형식으로 저장 중...\n",
      "   -> 저장 완료: train_new.jsonl (크기: 16632.91 KB)\n",
      "\n",
      "4. 파일 저장: val_new.jsonl에 JSONL 형식으로 저장 중...\n",
      "   -> 저장 완료: val_new.jsonl (크기: 4161.64 KB)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "# --- 설정 변수 ---\n",
    "INPUT_CSV_FILE = 'labeled_sentences.csv'\n",
    "TRAIN_OUTPUT_FILE = 'train_new.jsonl'\n",
    "VAL_OUTPUT_FILE = 'val_new.jsonl'\n",
    "TEST_SIZE_RATIO = 0.2  # 검증용 데이터셋 비율 (20%)\n",
    "RANDOM_STATE_SEED = 42 # 재현성을 위한 시드 설정\n",
    "\n",
    "# 헤더가 없는 파일이므로 컬럼 이름 임시 지정\n",
    "COLUMN_NAMES = ['text_input', 'command_string'] \n",
    "INSTRUCTION_TEXT = \"다음 문장의 감정에 어울리는 H,S,B,Dimmer,CT 값을 예측하세요. JSON으로만 답하세요.\"\n",
    "\n",
    "print(f\"1. 데이터 로드 및 파싱 준비: {INPUT_CSV_FILE}\")\n",
    "\n",
    "# 1. 데이터 로드: header=None으로 지정하고, names로 컬럼 이름 부여\n",
    "try:\n",
    "    # 쉼표(,)를 구분자로 사용하며, 헤더는 없고, 컬럼 이름을 직접 지정합니다.\n",
    "    df = pd.read_csv(\n",
    "        INPUT_CSV_FILE, \n",
    "        header=None, \n",
    "        names=COLUMN_NAMES, \n",
    "        sep=','\n",
    "    )\n",
    "    total_records = len(df)\n",
    "    \n",
    "    print(f\"   -> 로드된 총 레코드 수: {total_records}개 (3200개 가정)\")\n",
    "    print(f\"   -> 사용된 컬럼 목록: {list(df.columns)}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"에러: 파일을 찾을 수 없습니다! ({INPUT_CSV_FILE})\")\n",
    "    df = None\n",
    "except Exception as e:\n",
    "    print(f\"데이터 로드 중 예상치 못한 에러 발생: {e}\")\n",
    "    df = None\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "if df is not None and total_records > 0:\n",
    "    \n",
    "    # 2. command_string에서 H, S, B, Dimmer, CT 값을 파싱하여 새 컬럼 생성\n",
    "    def parse_command(command_str):\n",
    "        \"\"\"조명 명령 문자열에서 H, S, B, Dimmer, CT 값을 추출하여 딕셔너리로 반환\"\"\"\n",
    "        \n",
    "        # HSBCOLOR H,S,B 추출\n",
    "        hsb_match = re.search(r\"HSBCOLOR\\s*(\\d+),(\\d+),(\\d+)\", command_str)\n",
    "        # Dimmer D 추출\n",
    "        dimmer_match = re.search(r\"Dimmer\\s*(\\d+)\", command_str)\n",
    "        # CT C 추출\n",
    "        ct_match = re.search(r\"CT\\s*(\\d+)\", command_str)\n",
    "        \n",
    "        if hsb_match and dimmer_match and ct_match:\n",
    "            try:\n",
    "                h = int(hsb_match.group(1))\n",
    "                s = int(hsb_match.group(2))\n",
    "                b = int(hsb_match.group(3))\n",
    "                dimmer = int(dimmer_match.group(1))\n",
    "                ct = int(ct_match.group(1))\n",
    "                \n",
    "                return {'h': h, 's': s, 'b': b, 'dimmer': dimmer, 'ct': ct}\n",
    "            except ValueError:\n",
    "                # 숫자로 변환할 수 없는 경우 None 반환\n",
    "                return None\n",
    "        return None\n",
    "\n",
    "    # 파싱 함수를 모든 행에 적용\n",
    "    print(\"\\n2. 명령 문자열에서 H, S, B, Dimmer, CT 값 파싱 중...\")\n",
    "    df['output_dict'] = df['command_string'].apply(parse_command)\n",
    "    \n",
    "    # 파싱에 실패한 행(None) 제거 (데이터 클리닝)\n",
    "    df = df.dropna(subset=['output_dict'])\n",
    "    cleaned_records = len(df)\n",
    "    \n",
    "    if cleaned_records < total_records:\n",
    "        print(f\"   -> 파싱에 성공한 레코드 수: {cleaned_records}개 ({total_records - cleaned_records}개 제거됨)\")\n",
    "    else:\n",
    "        print(f\"   -> 파싱 성공 (총 {cleaned_records}개 레코드 사용)\")\n",
    "        \n",
    "    if cleaned_records == 0:\n",
    "        print(\"   -> 유효한 데이터가 없어 JSONL 파일 생성을 건너뜁니다.\")\n",
    "        exit() # 유효 데이터가 없으면 종료\n",
    "        \n",
    "    # 3. 데이터 분할: 80% train / 20% validation\n",
    "    print(f\"\\n3. 데이터 분할: Train ({1-TEST_SIZE_RATIO:.0%}) / Validation ({TEST_SIZE_RATIO:.0%})\")\n",
    "    \n",
    "    train_df, val_df = train_test_split(\n",
    "        df, \n",
    "        test_size=TEST_SIZE_RATIO, \n",
    "        random_state=RANDOM_STATE_SEED\n",
    "    )\n",
    "\n",
    "    print(f\"   -> 훈련 데이터셋 크기: {len(train_df)}개\")\n",
    "    print(f\"   -> 검증 데이터셋 크기: {len(val_df)}개\")\n",
    "\n",
    "    # 4. JSONL 형식으로 변환 및 파일 저장 함수\n",
    "    def save_to_jsonl(dataframe, filename):\n",
    "        \"\"\"DataFrame을 요청된 JSONL 형식으로 저장하는 함수\"\"\"\n",
    "        print(f\"\\n4. 파일 저장: {filename}에 JSONL 형식으로 저장 중...\")\n",
    "        \n",
    "        records = []\n",
    "        for index, row in dataframe.iterrows():\n",
    "            # 최종 JSONL 레코드 형식: { \"instruction\": \"...\", \"input\": \"...\", \"output\": { ... } }\n",
    "            records.append({\n",
    "                \"instruction\": INSTRUCTION_TEXT,\n",
    "                \"input\": row['text_input'],\n",
    "                \"output\": row['output_dict'] # 파싱된 딕셔너리 사용\n",
    "            })\n",
    "            \n",
    "        \n",
    "        # 파일에 JSONL 형식으로 쓰기\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            for record in records:\n",
    "                # 각 레코드를 JSON 문자열로 변환하고 줄바꿈(\\n) 추가\n",
    "                json_line = json.dumps(record, ensure_ascii=False)\n",
    "                f.write(json_line + '\\n')\n",
    "                \n",
    "        print(f\"   -> 저장 완료: {filename} (크기: {os.path.getsize(filename) / 1024:.2f} KB)\")\n",
    "\n",
    "\n",
    "    # 훈련 데이터 저장\n",
    "    save_to_jsonl(train_df, TRAIN_OUTPUT_FILE)\n",
    "    \n",
    "    # 검증 데이터 저장\n",
    "    save_to_jsonl(val_df, VAL_OUTPUT_FILE)\n",
    "\n",
    "else:\n",
    "    print(\"   -> 데이터 로드 실패 또는 데이터가 비어있어 파일 생성을 건너뜁니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentilight",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
